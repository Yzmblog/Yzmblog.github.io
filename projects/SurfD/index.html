<!DOCTYPE html
	PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
	<title>Surf-D: High-Quality Surface Generation for Arbitrary Topologies using Diffusion Models</title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

	<!-- Meta tags for Zotero grab citation -->
	<meta name="citation_title" content="Surf-D: High-Quality Surface Generation for Arbitrary Topologies using Diffusion Models">
	<meta name="citation_author" content="Zhengming Yu">
	<meta name="citation_author" content="Zhiyang Dou">
	<meta name="citation_author" content="Xiaoxiao Long">
	<meta name="citation_author" content="Cheng Lin">
	<meta name="citation_author" content="Zekun Li">
	<meta name="citation_author" content="Yuan Liu">
	<meta name="citation_author" content="Norman M&uuml;ller">
	<meta name="citation_author" content="Taku Komura">
	<meta name="citation_author" content="Marc Habermann">
	<meta name="citation_author" content="Christian Theobalt">
	<meta name="citation_author" content="Xin Li">
	<meta name="citation_author" content="Wang, Wenping">
	<meta name="citation_publication_date" content="2024">
	<!-- <meta name="citation_conference_title" content=""> -->
	<!-- <meta name="citation_pdf_url" content="http://arxiv.org/abs/xxx"> -->


	<meta name="robots" content="index,follow">
	<meta name="description"
		content="We present Surf-D, a novel method for generating high-quality 3D shapes as Surfaces with arbitrary topologies using Diffusion models">
	<link rel="author" href="" />


	<!-- Fonts and stuff -->
	<link href='http://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,800italic,400,700,800'
		rel='stylesheet' type='text/css'>
	<link rel="stylesheet" type="text/css" href="css/project.css" media="screen" />
	<link rel="stylesheet" type="text/css" media="screen" href="css/iconize.css" />
	<script src="js/google-code-prettify/prettify.js"></script>



	<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
});
</script>


</head>


<body>
	<div id="content">
		<div id="content-inner">
			<div class="section logos" style="text-align:center">
				<a href="https://www.tamu.edu/" target="_blank"><IMG src="./logos/Logo_TAMU.png" height="66" border="4"></a></td>
				<a href="https://www.hku.hk/" target="_blank"><IMG src="./logos/Logo_HKU.png" height="66" border="0"></a></td>
				<a href="https://www.mpi-inf.mpg.de/home" target="_blank"><IMG src="./logos/Logo_MPII.png" height="66" border="0"></a></td>
				<a href="https://www.brown.edu/" target="_blank"><IMG src="./logos/Logo_Brown.png" height="66" border="0"></a></td>
				<a href="https://about.meta.com/" target="_blank"><IMG src="./logos/Logo_Meta.png" height="66" border="0"></a></td>

			</div>


			<div class="section head">
				<h1>Surf-D: High-Quality Surface Generation for Arbitrary Topologies using Diffusion Models</h1>

				<div class="authors">
					<a href="https://yzmblog.github.io/" target="_blank">Zhengming Yu</a><sup> 1*</sup>&#160;&#160;
					<a href="https://frank-zy-dou.github.io/" target="_blank">Zhiyang Dou</a><sup> 2*</sup>&#160;&#160;
					<a href="https://www.xxlong.site/" target="_blank">Xiaoxiao Long</a><sup> 2, 3</sup>&#160;&#160;
					<a href="https://clinplayer.github.io/" target="_blank">Cheng Lin</a><sup> 2</sup>&#160;&#160;
					<a href="https://kunkun0w0.github.io/" target="_blank">Zekun Li</a><sup> 4</sup>&#160;&#160;
					<a href="https://liuyuan-pal.github.io/" target="_blank">Yuan Liu</a><sup> 2</sup>&#160;&#160;
					<br>
					<a href="https://niessnerlab.org/members/norman_mueller/profile.html" target="_blank">Norman M&uuml;ller</a><sup> 5</sup>&#160;&#160;
					<a href="https://i.cs.hku.hk/~taku/">Taku Komura</a><sup> 2</sup>&#160;&#160;
					<a href="https://people.mpi-inf.mpg.de/~mhaberma/" target="_blank">Marc Habermann</a><sup> 3</sup>&#160;&#160;
					<a href="https://people.mpi-inf.mpg.de/~theobalt/" target="_blank">Christian Theobalt</a><sup> 3</sup>&#160;&#160;
					<a href="https://people.tamu.edu/~xinli/" target="_blank">Xin Li</a><sup> 1</sup>&#160;&#160;
					<a href="https://engineering.tamu.edu/cse/profiles/Wang-Wenping.html">Wenping Wang</a><sup> 1</sup>&#160;&#160;
				</div>
				<div class="affiliations">
					<sup>1</sup><a href="https://www.tamu.edu/" target="_blank">Texas A&M University</a>&#160;&#160;
					<sup>2</sup><a href="https://www.hku.hk/" target="_blank">University of Hong Kong</a>&#160;&#160;
					<sup>3</sup><a href="https://www.mpi-inf.mpg.de/home" target="_blank">MPI Informatik</a>&#160;&#160;
					<sup>4</sup><a href="https://www.brown.edu/" target="_blank">Brown University</a>&#160;&#160;
					<sup>5</sup><a href="https://about.meta.com/" target="_blank">Meta Reality Labs Zurich</a>&#160;&#160;
				</div>
				<p>* Equal Contributions</p>

			</div>

			<div class="section downloads">
				<center>
					<ul style="padding-left: 0">
						<li class="grid">
							<div class="griditem">
								<a href="#"><img src="images/pdf.png"></a><br/>
								<a href="#">Paper</a>
							</div>
						</li>
						<!-- <li class="grid">
							<div class="griditem">
								<a href=""><img src="images/video.png"></a><br/>
								<a href="">Video</a>
							</div>
						</li> -->
						<li class="grid">
							<div class="griditem">
								<a href=""><img src="images/data_ico.png"></a><br/>
								<a href="">Code(Coming Soon)</a>

							</div>
						</li></ul>
				</center>
			</div>

			<div class="section abstract">
				<h2>Abstract</h2><br>
				<div class="row" style="margin-bottom:5px">
					<div class="col" style="text-align:center">
						<img class="thumbnail" src="figs/fig_teaser.png" style="width:100%; margin-bottom:20px">

					</div>
					<p>Our method achieves high-quality Surface generation for detailed geometry and various topology using a Diffusion model. It achieves SOTA performance in various shape generation tasks, including unconditional generation, category conditional generation, sketch conditional shape generation, single-view reconstruction, and text-guided shape generation.</p>

				</div>
				<p>
					We present <strong>Surf-D</strong>, a novel method for generating high-quality 3D shapes as <strong>Surfaces</strong> with arbitrary topologies using <strong>Diffusion</strong> models. Specifically, we adopt Unsigned Distance Field (UDF) as the surface representation,  as it excels in handling arbitrary topologies, enabling the generation of complex shapes. While the prior methods explored shape generation with different representations, they suffer from limited topologies and geometry details. Moreover, it's non-trivial to directly extend prior diffusion models to UDF because they lack spatial continuity due to the discrete volume structure. However, UDF requires accurate gradients for mesh extraction and learning. To tackle the issues, we first leverage a point-based auto-encoder to learn a compact latent space, which supports gradient querying for any input point through differentiation to effectively capture intricate geometry at a high resolution. Since the learning difficulty for various shapes can differ, a curriculum learning strategy is employed to efficiently embed various surfaces, enhancing the whole embedding process. With pretrained shape latent space, we employ a latent diffusion model to acquire the distribution of various shapes. Our approach demonstrates superior performance in shape generation across multiple modalities and conducts extensive experiments in unconditional generation, category conditional generation, 3D reconstruction from images, and text-to-shape tasks.
				</p>
			</div>
			<br>


			<div class="section abstract">
				<h2>Framework</h2>
				<center>
					<div class="row" style="margin-bottom:5px">
					<div class="col" style="text-align:center">
						<img class="thumbnail" src="figs/fig_pipeline.png" style="width:100%; margin-bottom:20px">
					</div>

					</div>
				</center>
			<p>In our framework, we first encode surface points into a latent code \( z \) by our encoder \( \mathcal{E} \). A curriculum scheduler helps to train our model in an easy-to-hard sample order. Then we train the diffusion model in our latent space and various conditions can be added by a task-specific encoder \( \tau \). Finally, the sampled latent code \( z \) will be decoded to a UDF field for mesh extraction by our UDF decoder \( \mathcal{D} \).
			</p>

			</div>
			<br>

			<div class="section abstract">
				<h2>Unconditional Generation</h2>
				<br>

				<center>
					<div class="row" style="margin-bottom:5px">
					<div class="col" style="text-align:center">
						<img class="thumbnail" src="figs/fig_unconditional.gif" style="width:100%; margin-bottom:20px">
					</div>
					</div>
				</center>
				<p>By unconditional sampling latent codes in latent space, <strong>Surf-D</strong> can produce high-quality and diverse shapes. We also calculate their average CD to each object in the training set to confirm that our model is capable of producing unique shapes.
				</p>
			</div>

			<div class="section abstract">
				<h2>Category Conditional Generation</h2><br>
				<center>
					<div class="row" style="margin-bottom:5px">
					<div class="col" style="text-align:center">
						<img class="thumbnail" src="figs/fig_cat_conditional.gif" style="width:100%; margin-bottom:20px">
					</div>
						<p>Given the category condition, <strong>Surf-D</strong> generates different categories of detailed 3D shapes with high-quality and diversity.</p>
					</div>
				</center>

			</div>


			<br>

			<div class="section abstract">
				<h2>Sketch Conditional Generation</h2>
				<br>
				
				<center>
					<div class="row" style="margin-bottom:5px">
					<div class="col" style="text-align:center">
						<img class="thumbnail" src="figs/fig_sketch2shape.png" style="width:100%; margin-bottom:20px">
					</div>
					<p>Under the sketch images condition, <strong>Surf-D</strong> generates higher quality and detailed results aligned with input sketch with arbitrary topology.</p>
					</div>
				</center>
			</div>

			<div class="section abstract">
				<h2>Generation for Virtual Try-on</h2><br>
				<center>
					<div class="row" style="margin-bottom:5px">
					<div class="col" style="text-align:center">
						<img class="thumbnail" src="figs/fig_virtual_try_on.gif" style="width:100%; margin-bottom:20px">
					</div>
					</div>
				</center>
			<p>We explore more applications that <strong>Surf-D</strong> can be applied to. As shown in the video, the clothes generated by <strong>Surf-D</strong> can be used for virtual try-on with high quality and fidelity.
			Imagine that you can just use sketches to generate whatever clothes you want, then put on your own avatar to try-on. Although it may sound crazy, this can be achieved with our proposed <strong>Surf-D</strong>!</p>

			</div>

			<div class="section abstract">
				<h2>Single-view Reconstruction</h2><br>
				<center>
					<div class="row" style="margin-bottom:5px">
					<div class="col" style="text-align:center">
						<img class="thumbnail" src="figs/fig_pix3d.png" style="width:100%; margin-bottom:20px">
					</div>
						<p>Given single-view images of objects, <strong>Surf-D</strong> can produce high-quality results faithfully aligned with input images.
						</p>
					</div>
				</center>

			</div>

			<div class="section abstract">
				<h2>Text-guided Generation</h2><br>
				<center>
					<div class="row" style="margin-bottom:5px">
					<div class="col" style="text-align:center">
						<img class="thumbnail" src="figs/fig_text2shape.png" style="width:60%; margin-bottom:20px">
					</div>
						<p>Give the text description of objects, <strong>Surf-D</strong> produces high-quality results aligned with input texts.
						</p>
					</div>
				</center>

			</div>			

			<center>
					<br>
									<h2 align="center">Check out our paper for more details.</h3>
				</center>
			</div>

			<!-- <div class="section list">
				<h2>Citation</h2>
				<div class="section bibtex">
					<pre>@article{
}
				</div>
			</div> -->
			
		</div>
	</div>
</body>
</html>